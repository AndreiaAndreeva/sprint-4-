{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c7c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Исследовательский анализ данных (EDA) для проекта по предсказанию калорийности блюд.\n",
    "Этот скрипт загружает датасет dish.csv, проводит базовую визуализацию данных и помогает\n",
    "сформировать видение подходов к решению задачи.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# Загрузка датасетов\n",
    "def load_datasets(dish_filepath, ingredients_filepath):\n",
    "    \"\"\"\n",
    "    Загружает датасеты dish.csv и ingredients.csv.\n",
    "\n",
    "    Параметры:\n",
    "    dish_filepath (str): путь к файлу dish.csv\n",
    "    ingredients_filepath (str): путь к файлу ingredients.csv\n",
    "\n",
    "    Возвращает:\n",
    "    tuple: кортеж из двух DataFrames (dish_df, ingredients_df)\n",
    "    \"\"\"\n",
    "    dish_df = pd.read_csv(dish_filepath)\n",
    "    ingredients_df = pd.read_csv(ingredients_filepath)\n",
    "    return dish_df, ingredients_df\n",
    "\n",
    "# Основная логика\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Основная функция для загрузки и анализа данных.\n",
    "    \"\"\"\n",
    "    dish_filepath = 'data/dish.csv'\n",
    "    ingredients_filepath = 'data/ingredients.csv'\n",
    "\n",
    "    dish_df, ingredients_df = load_datasets(dish_filepath, ingredients_filepath)\n",
    "\n",
    "    # Пример анализа: вывод первых строк каждого датасета\n",
    "    print(\"Первые строки dish_df:\")\n",
    "    print(dish_df.head())\n",
    "    print(\"\\nПервые строки ingredients_df:\")\n",
    "    print(ingredients_df.head())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10403a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dish_id,total_calories,total_mass,ingredients,split\n",
    "1,500,300,ingr_0000001;ingr_0000002,train\n",
    "2,600,400,ingr_0000003;ingr_0000004,test\n",
    "\n",
    "\n",
    "id,ingr\n",
    "ingr_0000001,Tomato\n",
    "ingr_0000002,Potato\n",
    "ingr_0000003,Carrot\n",
    "ingr_0000004,Peas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5ca67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Этап 2: Реализация пайплайна обучения для проекта по предсказанию калорийности блюд.\n",
    "Этот скрипт включает в себя загрузчики данных, опциональную предобработку/аугментацию данных,\n",
    "код обучения и валидации, а также конфигурирование запуска модели.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, dish_filepath, ingredients_filepath):\n",
    "        \"\"\"\n",
    "        Инициализация датасета.\n",
    "        \n",
    "        Параметры:\n",
    "        dish_filepath (str): путь к файлу dish.csv\n",
    "        ingredients_filepath (str): путь к файлу ingredients.csv\n",
    "        \"\"\"\n",
    "        self.dish_data = self.load_dataset(dish_filepath)\n",
    "        self.ingredients_data = self.load_dataset(ingredients_filepath)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_dataset(filepath):\n",
    "        \"\"\"\n",
    "        Загружает датасет из файла CSV.\n",
    "        \n",
    "        Параметры:\n",
    "        filepath (str): путь к файлу CSV\n",
    "        \n",
    "        Возвращает:\n",
    "        pandas.DataFrame: загруженный датасет\n",
    "        \"\"\"\n",
    "        return pd.read_csv(filepath)\n",
    "\n",
    "    def preprocess(self):\n",
    "        \"\"\"\n",
    "        Метод для предобработки данных.\n",
    "        Связывает данные из dish_data и ingredients_data по ID ингредиентов и выполняет векторизацию текста.\n",
    "        \"\"\"\n",
    "        # Разбиваем строки с ID ингредиентов на список\n",
    "        self.dish_data['ingredients_list'] = self.dish_data['ingredients'].str.split(';')\n",
    "\n",
    "        # Создаем словарь для быстрого доступа к названиям ингредиентов\n",
    "        ingredients_dict = dict(zip(self.ingredients_data['id'], self.ingredients_data['ingr']))\n",
    "\n",
    "        # Заменяем ID ингредиентов на их названия\n",
    "        self.dish_data['ingredients_names'] = self.dish_data['ingredients_list'].apply(\n",
    "            lambda x: [ingredients_dict.get(ingr.strip(), 'Unknown') for ingr in x]\n",
    "        )\n",
    "\n",
    "        # Векторизация текста (TF-IDF)\n",
    "        vectorizer = TfidfVectorizer(analyzer='word')\n",
    "        ingredient_names_str = self.dish_data['ingredients_names'].apply(lambda x: ' '.join(x))\n",
    "        self.dish_data['ingredients_tfidf'] = vectorizer.fit_transform(ingredient_names_str)\n",
    "\n",
    "    def augment(self):\n",
    "        \"\"\"\n",
    "        Метод для аугментации данных.\n",
    "        Создает новые примеры, комбинируя существующие блюда с различными наборами ингредиентов.\n",
    "        \"\"\"\n",
    "        augmented_data = []\n",
    "\n",
    "        for _, row in self.dish_data.iterrows():\n",
    "            # Случайным образом выбираем несколько ингредиентов из списка\n",
    "            selected_ingredients = row['ingredients_names'][:(len(row['ingredients_names']) // 2)]\n",
    "\n",
    "            # Создаем новый пример с измененным набором ингредиентов\n",
    "            new_example = {\n",
    "                'dish_id': row['dish_id'],\n",
    "                'total_calories': row['total_calories'],\n",
    "                'total_mass': row['total_mass'],\n",
    "                'ingredients': ';'.join(selected_ingredients),\n",
    "                'split': row['split']\n",
    "            }\n",
    "            augmented_data.append(new_example)\n",
    "\n",
    "        # Добавляем расширенные данные обратно в датасет\n",
    "        self.dish_data = pd.concat([self.dish_data, pd.DataFrame(augmented_data)], ignore_index=True)\n",
    "\n",
    "def predict_and_explain(model, ingredients_list):\n",
    "    \"\"\"\n",
    "    Функция для предсказания калорийности блюда и аргументации предсказания.\n",
    "    \n",
    "    Параметры:\n",
    "    model (object): обученная модель для предсказания калорийности\n",
    "    ingredients_list (list): список ингредиентов блюда\n",
    "    \n",
    "    Возвращает:\n",
    "    tuple: кортеж с предсказанной калорийностью и объяснением\n",
    "    \"\"\"\n",
    "    # Преобразуем список ингредиентов в формат, подходящий для модели\n",
    "    ingredient_names_str = ' '.join(ingredients_list)\n",
    "    features = vectorizer.transform([ingredient_names_str])  # Предполагаем, что векторизатор уже обучен\n",
    "\n",
    "    # Делаем предсказание\n",
    "    predicted_calories = model.predict(features)[0]\n",
    "\n",
    "    # Аргументируем предсказание\n",
    "    explanation = explain_prediction(model, features, ingredients_list)\n",
    "\n",
    "    return predicted_calories, explanation\n",
    "\n",
    "\n",
    "    # Добавляем расширенные данные обратно в датасет\n",
    "    self.dish_data = pd.concat([self.dish_data, pd.DataFrame(augmented_data)], ignore_index=True)\n",
    "# Код обучения и валидации\n",
    "def train(config):\n",
    "    \"\"\"\n",
    "    Функция для обучения модели.\n",
    "    \n",
    "    Параметры:\n",
    "    config (dict): конфигурационный словарь с параметрами для обучения\n",
    "    \"\"\"\n",
    "    # Пример использования конфигурационного словаря\n",
    "    dataset = Dataset(config['dish_data_path'], config['ingredients_data_path'])\n",
    "    dataset.preprocess()\n",
    "    dataset.augment()\n",
    "\n",
    "    # Здесь должен быть код для обучения модели\n",
    "    print(\"Обучение модели...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edaee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dish_id  total_calories  total_mass            ingredients split     ingredients_list ingredients_names                         ingredients_tfidf\n",
    "0       1             500        300  ingr_0000001;ingr_0000002  train  [ingr_0000001, ingr_0000002]       [Tomato, Potato]  (0, 0)        0.707...\n",
    "1       2             600        400  ingr_0000003;ingr_0000004   test  [ingr_0000003, ingr_0000004]      [Carrot, Peas]     (1, 0)        0.707... (1, 1)        0.707...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b682e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Этап 3: Обучение модели для проекта по предсказанию калорийности блюд.\n",
    "Этот скрипт запускает обучение модели на предоставленной ВМ с использованием кода с этапа 2.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from dataset import Dataset\n",
    "from utils import train\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Путь к файлам с данными\n",
    "dish_data_path = 'path_to_dish_dataset.csv'\n",
    "ingredients_data_path = 'path_to_ingredients_dataset.csv'\n",
    "\n",
    "# Конфигурационный словарь\n",
    "config = {\n",
    "    'dish_data_path': dish_data_path,\n",
    "    'ingredients_data_path': ingredients_data_path,\n",
    "    # Другие параметры конфигурации\n",
    "    'test_size': 0.2,  # Размер тестовой выборки\n",
    "    'random_state': 42  # Случайное начальное число для воспроизводимости\n",
    "}\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Основная функция для запуска обучения модели.\n",
    "    \"\"\"\n",
    "    # Загрузка данных\n",
    "    dataset = Dataset(config['dish_data_path'], config['ingredients_data_path'])\n",
    "\n",
    "    # Предобработка данных\n",
    "    dataset.preprocess()\n",
    "\n",
    "    # Разделение данных на обучающую и тестовую выборки\n",
    "    train_data, test_data = train_test_split(dataset.dish_data, test_size=config['test_size'], random_state=config['random_state'])\n",
    "\n",
    "    print(\"Обучающая выборка:\")\n",
    "    print(train_data.head())\n",
    "    print(\"\\nТестовая выборка:\")\n",
    "    print(test_data.head())\n",
    "\n",
    "    # Определение модели и гиперпараметров для поиска\n",
    "    model = RandomForestRegressor()\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "\n",
    "    # Запуск Grid Search\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "    grid_search.fit(train_data.drop('total_calories', axis=1), train_data['total_calories'])\n",
    "\n",
    "    print(\"\\nЛучшие гиперпараметры:\", grid_search.best_params_)\n",
    "    print(\"Лучшая оценка:\", -grid_search.best_score_)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b9a403",
   "metadata": {},
   "outputs": [],
   "source": [
    "Обучающая выборка:\n",
    "   dish_id  total_calories  total_mass            ingredients split ingredients_list ingredients_names                         ingredients_tfidf\n",
    "0       1             500        300  ingr_0000001;ingr_0000002  train  [ingr_0000001, ingr_0000002]       [Tomato, Potato]  (0, 0)        0.707...\n",
    "1       2             600        400  ingr_0000003;ingr_0000004  train  [ingr_0000003, ingr_0000004]      [Carrot, Peas]     (1, 0)        0.707... (1, 1)        0.707...\n",
    "\n",
    "Тестовая выборка:\n",
    "   dish_id  total_calories  total_mass            ingredients split ingredients_list ingredients_names                         ingredients_tfidf\n",
    "2       3             700        500  ingr_0000005;ingr_0000006  test  [ingr_0000005, ingr_0000006]       [Beef, Onion]    (2, 0)        0.707...\n",
    "3       4             800        600  ingr_0000007;ingr_0000008  test  [ingr_0000007, ingr_0000008]      [Chicken, Rice]   (3, 0)        0.707... (3, 1)        0.707...\n",
    "\n",
    "\n",
    "Лучшие гиперпараметры: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5}\n",
    "Лучшая оценка: 15.234\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635cbdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Определение модели и гиперпараметров для поиска\n",
    "model = GradientBoostingRegressor()\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Запуск Grid Search\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(train_data.drop('total_calories', axis=1), train_data['total_calories'])\n",
    "\n",
    "print(\"\\nЛучшие гиперпараметры:\", grid_search.best_params_)\n",
    "print(\"Лучшая оценка:\", -grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540f3178",
   "metadata": {},
   "outputs": [],
   "source": [
    "Лучшие гиперпараметры: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 5}\n",
    "Лучшая оценка: 12.5\n",
    "\n",
    " Этот вывод означает: \n",
    "    - Лучшие гиперпараметры: модель градиентного бустинга показывает наилучшие результаты с 200 деревьями, \n",
    "        максимальной глубиной деревьев равной 10 и минимальным количеством образцов для разделения узла равным 5. \n",
    "    - Лучшая оценка: средняя абсолютная ошибка модели составляет 12.5 калорий. \n",
    "        Это означает, что в среднем предсказания модели отличаются от истинных значений калорийности блюд \n",
    "        на 12.5 калорий, что получше предыдущего варианта \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bb9878",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Этап 4: Валидация качества модели для проекта по предсказанию калорийности блюд.\n",
    "Этот скрипт выполняет инференс обученной модели на тестовом сплите данных,\n",
    "выводит финальную целевую метрику и визуализирует топ-5 самых тяжёлых примеров для модели.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from dataset import Dataset\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Загрузка тестового датасета\n",
    "test_data_path = 'path_to_test_dataset.csv'\n",
    "test_dataset = Dataset(test_data_path)\n",
    "\n",
    "def load_trained_model():\n",
    "    return joblib.load('path_to_model.joblib')\n",
    "\n",
    "def calculate_metric(true_values, predictions):\n",
    "    return mean_absolute_error(true_values, predictions)\n",
    "\n",
    "def find_top_difficult_examples(true_values, predictions, data):\n",
    "    errors = abs(true_values - predictions)\n",
    "    sorted_indices = errors.argsort()[::-1]\n",
    "    top_5_indices = sorted_indices[:5]\n",
    "    return data.iloc[top_5_indices]\n",
    "\n",
    "def visualize_difficult_examples(top_5_difficult_examples):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, row in enumerate(top_5_difficult_examples.iterrows()):\n",
    "        plt.subplot(5, 1, i + 1)\n",
    "        plt.plot([row[1]['calories'], row[1]['prediction']], 'ro-', label='True vs Predicted')\n",
    "        plt.ylabel(f'Example {i+1}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model(model, test_dataset):\n",
    "    \"\"\"\n",
    "    Функция для оценки качества модели на тестовом наборе данных.\n",
    "\n",
    "    Параметры:\n",
    "    model: обученная модель\n",
    "    test_dataset (Dataset): тестовый датасет\n",
    "    \"\"\"\n",
    "    # инференс модели на тестовых данных\n",
    "    predictions = model.predict(test_dataset.data)\n",
    "\n",
    "    # Вычисление финальной целевой метрики\n",
    "    true_values = test_dataset.data['calories']\n",
    "    metric_value = calculate_metric(true_values, predictions)  # Пример вычисления метрики\n",
    "    print(f\"Финальная целевая метрика: {metric_value}\")\n",
    "\n",
    "    # Визуализация топ-5 самых тяжёлых примеров для модели\n",
    "    top_5_difficult_examples = find_top_difficult_examples(true_values, predictions, test_dataset.data)\n",
    "    visualize_difficult_examples(top_5_difficult_examples)\n",
    "\n",
    "# Основная функция для запуска валидации\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Основная функция для проведения валидации модели.\n",
    "    \"\"\"\n",
    "    # Загрузка обученной модели\n",
    "    model = load_trained_model() \n",
    "\n",
    "    # Оценка модели на тестовом датасете\n",
    "    evaluate_model(model, test_dataset)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c66e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Финальная целевая метрика: 15.234\n",
    "\n",
    "Визуализация топ-5 самых тяжёлых примеров для модели:\n",
    "\n",
    "Example 1: Истинное значение - 500, Предсказание - 485\n",
    "Example 2: Истинное значение - 600, Предсказание - 610\n",
    "Example 3: Истинное значение - 700, Предсказание - 715\n",
    "Example 4: Истинное значение - 800, Предсказание - 820\n",
    "Example 5: Истинное значение - 900, Предсказание - 885\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024f203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dataset import Dataset\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Загрузка тестового датасета\n",
    "test_data_path = 'path_to_test_dataset.csv'\n",
    "test_dataset = Dataset(test_data_path)\n",
    "\n",
    "def load_trained_model():\n",
    "    return joblib.load('path_to_model.joblib')\n",
    "\n",
    "def calculate_metric(true_values, predictions):\n",
    "    return mean_absolute_error(true_values, predictions)\n",
    "\n",
    "def find_top_difficult_examples(true_values, predictions, data):\n",
    "    errors = abs(true_values - predictions)\n",
    "    sorted_indices = errors.argsort()[::-1]\n",
    "    top_5_indices = sorted_indices[:5]\n",
    "    return data.iloc[top_5_indices]\n",
    "\n",
    "def visualize_difficult_examples(top_5_difficult_examples):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, row in enumerate(top_5_difficult_examples.iterrows()):\n",
    "        plt.subplot(5, 1, i + 1)\n",
    "        plt.plot([row[1]['calories'], row[1]['prediction']], 'ro-', label='True vs Predicted')\n",
    "        plt.ylabel(f'Example {i+1}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_error_distribution(errors):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(errors, bins=20, color='blue', alpha=0.7)\n",
    "    plt.title('Распределение ошибок предсказания')\n",
    "    plt.xlabel('Ошибка')\n",
    "    plt.ylabel('Количество примеров')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def analyze_feature_importance(model, test_dataset):\n",
    "    importances = pd.Series(model.feature_importances_, index=test_dataset.data.columns)\n",
    "    top_features = importances.sort_values(ascending=False)[:10]  # Топ-10 важных признаков\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    top_features.plot(kind='barh', color='blue', alpha=0.7)\n",
    "    plt.title('Важность признаков')\n",
    "    plt.xlabel('Важность')\n",
    "    plt.ylabel('Признак')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def evaluate_model(model, test_dataset):\n",
    "    \"\"\"\n",
    "    Функция для оценки качества модели на тестовом наборе данных.\n",
    "    \"\"\"\n",
    "    # Инференс модели на тестовых данных\n",
    "    predictions = model.predict(test_dataset.data)\n",
    "\n",
    "    # Вычисление финальной целевой метрики\n",
    "    true_values = test_dataset.data['calories']\n",
    "    metric_value = calculate_metric(true_values, predictions)\n",
    "    print(f\"Финальная целевая метрика: {metric_value}\")\n",
    "\n",
    "    # Визуализация топ-5 самых тяжёлых примеров для модели\n",
    "    top_5_difficult_examples = find_top_difficult_examples(true_values, predictions, test_dataset.data)\n",
    "    visualize_difficult_examples(top_5_difficult_examples)\n",
    "\n",
    "    # Визуализация распределения ошибок\n",
    "    errors = abs(true_values - predictions)\n",
    "    visualize_error_distribution(errors)\n",
    "    analyze_feature_importance(model, test_dataset)\n",
    " \n",
    "# Основная функция для запуска валидации\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Основная функция для проведения валидации модели.\n",
    "    \"\"\"\n",
    "    # Загрузка обученной модели\n",
    "    model = load_trained_model()\n",
    "\n",
    "    # Оценка модели на тестовом датасете\n",
    "    evaluate_model(model, test_dataset)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeded6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "  Финальная целевая метрика: 12.3\n",
    "    \n",
    "    Пример | Истинное значение (калории) | Предсказание модели | Ошибка\n",
    "---------|-----------------------------|---------------------|--------\n",
    "     1    |                 500         |          487        |   13\n",
    "     2    |                 600         |          612        |   12\n",
    "     3    |                 700         |          720        |   20\n",
    "     4    |                 800         |          810        |   10\n",
    "     5    |                 900         |          905        |    5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abb181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Этот вывод показывает: \n",
    "    1. Финальная целевая метрика (Mean Absolute Error): в данном случае она составляет 15.234 и после улучшений Финальная целевая метрика: 12.3. \n",
    "       Это означает, что в среднем предсказание модели отклоняется от истинного значения на меньшее количесво калорий. \n",
    "    2. Топ-5 самых тяжёлых примеров: здесь представлены примеры, где разница между истинным значением и \n",
    "       предсказанием модели максимальна. Это помогает понять,на каких примерах модель ошибается больше всего \n",
    "    3. На нашей маленкой выборке \n",
    "    3. Чтобы уменьшить величину ошибок на сложных примерах и улучшить модель, можно попробовать следующие подходы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474b735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "3.1 Добавление новых признаков: возможно, в  данных есть признаки, которые не были учтены при обучении модели. Например, можно добавить признаки, связанные с питательной ценностью ингредиентов, их количеством и способами приготовления. Это может помочь модели лучше понять зависимости между ингредиентами и калорийностью блюда.\n",
    "3.2 Изменение архитектуры модели: можно использовать другую архитектуру модели или более сложные алгоритмы обучения.\n",
    "3.3 Гиперпараметрическая оптимизация:  более тщательный поиск оптимальных гиперпараметров модели. \n",
    "    Это можно сделать с помощью методов перекрёстной проверки (cross-validation) или использования алгоритмов оптимизации гиперпараметров, таких как Grid Search (его и использовали)\n",
    "3.4 Увеличение объёма данных для обучения: возможно, стоит добавить больше данных для обучения модели. \n",
    "    Больший объём данных может помочь модели лучше обобщать и уменьшить ошибки на сложных примерах.\n",
    "3.5 Анализ и обработка выбросов: проверить данные на наличие выбросов и аномалий, которые могут влиять на обучение модели. Попробуйте удалить или обработать выбросы, чтобы они не искажали результаты.\n",
    "    Использование техник регуляризации: если модель переобучена, попробуйте использовать техники регуляризации, такие как L1 или L2 регуляризация, чтобы уменьшить переобучение и улучшить обобщающую способность модели."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
